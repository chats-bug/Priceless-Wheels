{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-04-04T16:36:54.147343Z",
     "iopub.execute_input": "2023-04-04T16:36:54.147767Z",
     "iopub.status.idle": "2023-04-04T16:36:54.158057Z",
     "shell.execute_reply.started": "2023-04-04T16:36:54.147728Z",
     "shell.execute_reply": "2023-04-04T16:36:54.156708Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/input/transformed-data/transformed.csv\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:36:54.504044Z",
     "iopub.execute_input": "2023-04-04T16:36:54.504465Z",
     "iopub.status.idle": "2023-04-04T16:36:54.512534Z",
     "shell.execute_reply.started": "2023-04-04T16:36:54.504429Z",
     "shell.execute_reply": "2023-04-04T16:36:54.511320Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/input/transformed-data/transformed.csv\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('/kaggle/input/transformed-data/transformed.csv')\n",
    "INDEX = 'usedCarSkuId'\n",
    "TARGET = 'listed_price'\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:36:54.946327Z",
     "iopub.execute_input": "2023-04-04T16:36:54.946712Z",
     "iopub.status.idle": "2023-04-04T16:36:56.858896Z",
     "shell.execute_reply.started": "2023-04-04T16:36:54.946680Z",
     "shell.execute_reply": "2023-04-04T16:36:56.857306Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "execution_count": 6,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                           usedCarSkuId  myear       body transmission fuel  \\\n0  7111bf25-97af-47f9-867b-40879190d800   2016  hatchback       manual  cng   \n1  c309efc1-efaf-4f82-81ad-dcb38eb36665   2015  hatchback       manual  cng   \n2  7609f710-0c97-4f00-9a47-9b9284b62d3a   2015      sedan       manual  cng   \n3  278b76e3-5539-4a5e-ae3e-353a2e3b6d7d   2013  hatchback       manual  cng   \n4  b1eab99b-a606-48dd-a75b-57feb8a9ad92   2022        muv       manual  cng   \n\n   km_driven  ip     oem           model        variant  ... Cargo Volume  \\\n0      69162   0  maruti  maruti wagon r        lxi cng  ...   180-liters   \n1      45864   0  maruti  maruti celerio      green vxi  ...   235-litres   \n2      81506   0   honda     honda amaze  s plus i-vtec  ...   400-litres   \n3     115893   0  maruti  maruti wagon r        lxi cng  ...          NaN   \n4      18900   0  maruti   maruti ertiga        vxi cng  ...          NaN   \n\n           state mileage_new owner_type           Fuel Suppy System  \\\n0  uttar pradesh       26.60      first                         NaN   \n1    maharashtra       31.79      first     Gasoline Port Injection   \n2          delhi       18.00     second                         NaN   \n3          delhi       26.20     second  Multi-Point Fuel Injection   \n4    maharashtra       26.11      first                         NaN   \n\n  Alloy Wheel Size Max Power Delivered Max Power At Max Torque Delivered  \\\n0              NaN               58.16       6200.0                 77.0   \n1              NaN               58.20       6000.0                 78.0   \n2              NaN               86.70       6000.0                109.0   \n3             13.0               58.20       6200.0                 77.0   \n4              NaN               86.63       5500.0                121.5   \n\n  Max Torque At  \n0        3500.0  \n1        3500.0  \n2        4500.0  \n3        3500.0  \n4        4200.0  \n\n[5 rows x 51 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usedCarSkuId</th>\n      <th>myear</th>\n      <th>body</th>\n      <th>transmission</th>\n      <th>fuel</th>\n      <th>km_driven</th>\n      <th>ip</th>\n      <th>oem</th>\n      <th>model</th>\n      <th>variant</th>\n      <th>...</th>\n      <th>Cargo Volume</th>\n      <th>state</th>\n      <th>mileage_new</th>\n      <th>owner_type</th>\n      <th>Fuel Suppy System</th>\n      <th>Alloy Wheel Size</th>\n      <th>Max Power Delivered</th>\n      <th>Max Power At</th>\n      <th>Max Torque Delivered</th>\n      <th>Max Torque At</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7111bf25-97af-47f9-867b-40879190d800</td>\n      <td>2016</td>\n      <td>hatchback</td>\n      <td>manual</td>\n      <td>cng</td>\n      <td>69162</td>\n      <td>0</td>\n      <td>maruti</td>\n      <td>maruti wagon r</td>\n      <td>lxi cng</td>\n      <td>...</td>\n      <td>180-liters</td>\n      <td>uttar pradesh</td>\n      <td>26.60</td>\n      <td>first</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>58.16</td>\n      <td>6200.0</td>\n      <td>77.0</td>\n      <td>3500.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c309efc1-efaf-4f82-81ad-dcb38eb36665</td>\n      <td>2015</td>\n      <td>hatchback</td>\n      <td>manual</td>\n      <td>cng</td>\n      <td>45864</td>\n      <td>0</td>\n      <td>maruti</td>\n      <td>maruti celerio</td>\n      <td>green vxi</td>\n      <td>...</td>\n      <td>235-litres</td>\n      <td>maharashtra</td>\n      <td>31.79</td>\n      <td>first</td>\n      <td>Gasoline Port Injection</td>\n      <td>NaN</td>\n      <td>58.20</td>\n      <td>6000.0</td>\n      <td>78.0</td>\n      <td>3500.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7609f710-0c97-4f00-9a47-9b9284b62d3a</td>\n      <td>2015</td>\n      <td>sedan</td>\n      <td>manual</td>\n      <td>cng</td>\n      <td>81506</td>\n      <td>0</td>\n      <td>honda</td>\n      <td>honda amaze</td>\n      <td>s plus i-vtec</td>\n      <td>...</td>\n      <td>400-litres</td>\n      <td>delhi</td>\n      <td>18.00</td>\n      <td>second</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>86.70</td>\n      <td>6000.0</td>\n      <td>109.0</td>\n      <td>4500.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>278b76e3-5539-4a5e-ae3e-353a2e3b6d7d</td>\n      <td>2013</td>\n      <td>hatchback</td>\n      <td>manual</td>\n      <td>cng</td>\n      <td>115893</td>\n      <td>0</td>\n      <td>maruti</td>\n      <td>maruti wagon r</td>\n      <td>lxi cng</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>delhi</td>\n      <td>26.20</td>\n      <td>second</td>\n      <td>Multi-Point Fuel Injection</td>\n      <td>13.0</td>\n      <td>58.20</td>\n      <td>6200.0</td>\n      <td>77.0</td>\n      <td>3500.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b1eab99b-a606-48dd-a75b-57feb8a9ad92</td>\n      <td>2022</td>\n      <td>muv</td>\n      <td>manual</td>\n      <td>cng</td>\n      <td>18900</td>\n      <td>0</td>\n      <td>maruti</td>\n      <td>maruti ertiga</td>\n      <td>vxi cng</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>maharashtra</td>\n      <td>26.11</td>\n      <td>first</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>86.63</td>\n      <td>5500.0</td>\n      <td>121.5</td>\n      <td>4200.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 51 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "class FeatureEngineeringTransformations(BaseEstimator):\n",
    "    \"\"\"\n",
    "    This class contains all the recommended feature engineering transformations for the dataset.\n",
    "\n",
    "    :parameter\n",
    "        df: pd.DataFrame\n",
    "            The dataframe to be transformed\n",
    "        object_cols: list\n",
    "            The list of columns that contain the car features like top_features, comfort_features, etc. that need to be transformed\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            df: pd.DataFrame,\n",
    "            object_cols=None\n",
    "    ):\n",
    "        if object_cols is None:\n",
    "            object_cols = [\n",
    "                'top_features',\n",
    "                'comfort_features',\n",
    "                'interior_features',\n",
    "                'exterior_features',\n",
    "                'safety_features'\n",
    "            ]\n",
    "        self.df = df.copy()\n",
    "        self.object_cols = object_cols\n",
    "        self.feature_prices = None\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def _car_object_feature_dict(self) -> dict:\n",
    "        unique_feature_scores = dict()\n",
    "        for col in self.object_cols:\n",
    "            for _, row in self.df.iterrows():\n",
    "                feature_list = literal_eval(row[col])\n",
    "                for feature in feature_list:\n",
    "                    if feature in unique_feature_scores.keys():\n",
    "                        unique_feature_scores[feature][1] += 1\n",
    "                        unique_feature_scores[feature][0] += row[TARGET]\n",
    "                    else:\n",
    "                        unique_feature_scores[feature] = [row[TARGET], 1]\n",
    "\n",
    "        return unique_feature_scores\n",
    "\n",
    "    def _map_object_cols_to_scores(self, x: str) -> float:\n",
    "        feature_list = literal_eval(x)\n",
    "        feature_score = 0\n",
    "        for feature in feature_list:\n",
    "            if feature in self.feature_prices.keys():\n",
    "                feature_score += self.feature_prices[feature][0] / self.feature_prices[feature][1]\n",
    "            else:\n",
    "                feature_score += 0\n",
    "        return feature_score\n",
    "\n",
    "    def _car_object_feature_transformation(self, df) -> pd.DataFrame:\n",
    "        if self.feature_prices is None:\n",
    "            raise Exception('Please fit the transformer first')\n",
    "\n",
    "        for col in self.object_cols:\n",
    "            df[f'{col}_score'] = df[col].apply(self._map_object_cols_to_scores)\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "            # Replace zero scores with nan\n",
    "            df[f'{col}_score'] = df[f'{col}_score'].replace(0, np.nan)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.feature_prices = self._car_object_feature_dict()\n",
    "        self.df = self._car_object_feature_transformation(self.df)\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if not self.is_fitted:\n",
    "            raise Exception('Please fit the transformer first')\n",
    "        \n",
    "        df = df.copy()\n",
    "        # Transform the object columns to scores\n",
    "        df = self._car_object_feature_transformation(df)\n",
    "        return df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:36:56.861934Z",
     "iopub.execute_input": "2023-04-04T16:36:56.862341Z",
     "iopub.status.idle": "2023-04-04T16:36:56.880487Z",
     "shell.execute_reply.started": "2023-04-04T16:36:56.862303Z",
     "shell.execute_reply": "2023-04-04T16:36:56.878808Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training and Testing Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_training_testing_validation_data(df: pd.DataFrame) -> tuple:\n",
    "    keep, val = train_test_split(df, test_size=0.1, random_state=42)\n",
    "    # Do not touch the val data, it will be used for the final final evalutation\n",
    "    # The val data would be split into 2 parts:\n",
    "    # 1. The first part val_1 will be used to determine the best model out of the HP optimized models\n",
    "    # 2. The second part val_2 will serve as our final scores\n",
    "\n",
    "    train, test = train_test_split(keep, test_size=0.2, random_state=42)\n",
    "    return train, test, val"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:36:57.238267Z",
     "iopub.execute_input": "2023-04-04T16:36:57.239415Z",
     "iopub.status.idle": "2023-04-04T16:36:57.366979Z",
     "shell.execute_reply.started": "2023-04-04T16:36:57.239361Z",
     "shell.execute_reply": "2023-04-04T16:36:57.365647Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train, test, valid = get_training_testing_validation_data(df)\n",
    "\n",
    "# Do the feature engineering transformations\n",
    "fe = FeatureEngineeringTransformations(train)\n",
    "fe = fe.fit()\n",
    "\n",
    "train = fe.transform(train)\n",
    "test = fe.transform(test)\n",
    "valid = fe.transform(valid)\n",
    "\n",
    "train.shape, test.shape, valid.shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:36:57.569182Z",
     "iopub.execute_input": "2023-04-04T16:36:57.569673Z",
     "iopub.status.idle": "2023-04-04T16:37:31.175607Z",
     "shell.execute_reply.started": "2023-04-04T16:36:57.569632Z",
     "shell.execute_reply": "2023-04-04T16:37:31.174211Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "execution_count": 9,
     "output_type": "execute_result",
     "data": {
      "text/plain": "((27113, 51), (6779, 51), (3766, 51))"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = train.drop(columns=[TARGET], axis=1).reset_index(drop=True)\n",
    "y_train = train[TARGET].reset_index(drop=True)\n",
    "X_test = test.drop(columns=[TARGET], axis=1).reset_index(drop=True)\n",
    "y_test = test[TARGET].reset_index(drop=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:37:31.178625Z",
     "iopub.execute_input": "2023-04-04T16:37:31.180033Z",
     "iopub.status.idle": "2023-04-04T16:37:31.212436Z",
     "shell.execute_reply.started": "2023-04-04T16:37:31.179972Z",
     "shell.execute_reply": "2023-04-04T16:37:31.210964Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre Processor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "bool_cols = X_train.select_dtypes(include=['bool']).columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "onehot_cols = [col for col in categorical_cols if X_train[col].nunique() < 50]\n",
    "target_cols = [col for col in categorical_cols if col not in onehot_cols]\n",
    "all_cols = X_train.columns\n",
    "\n",
    "numerical_transformer = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "boolean_transformer = Pipeline(\n",
    "    [\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('bool', boolean_transformer, bool_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder='drop',\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:37:31.213906Z",
     "iopub.execute_input": "2023-04-04T16:37:31.214244Z",
     "iopub.status.idle": "2023-04-04T16:37:31.326438Z",
     "shell.execute_reply.started": "2023-04-04T16:37:31.214213Z",
     "shell.execute_reply": "2023-04-04T16:37:31.324945Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_model = xgboost.XGBRegressor(\n",
    "    objective = 'reg:linear',\n",
    "    learning_rate = 0.08363996779482333,\n",
    "    max_depth = 7,\n",
    "    min_child_samples = 14,\n",
    "    subsample = 0.8130687216963774,\n",
    "    colsample_bytree = 0.726149859230546,\n",
    "    reg_alpha = 6.495685321153756,\n",
    "    reg_lambda = 0.004206014748968054,\n",
    "    n_estimators = 1000,\n",
    "    importance_type = 'gain',\n",
    "    verbose = 1,\n",
    "    min_split_gain = 0.0,\n",
    "    random_state=42,\n",
    "    tree_method = \"hist\", # change to gpu_hist if a gpu is available\n",
    "    single_precision_histogram=True,\n",
    "    n_jobs=-1\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:39:09.949983Z",
     "iopub.execute_input": "2023-04-04T16:39:09.950505Z",
     "iopub.status.idle": "2023-04-04T16:39:10.071207Z",
     "shell.execute_reply.started": "2023-04-04T16:39:09.950467Z",
     "shell.execute_reply": "2023-04-04T16:39:10.069486Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a pipeline to preprocess the data and train the model\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb_model)\n",
    "])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:39:12.981436Z",
     "iopub.execute_input": "2023-04-04T16:39:12.981875Z",
     "iopub.status.idle": "2023-04-04T16:39:12.988733Z",
     "shell.execute_reply.started": "2023-04-04T16:39:12.981826Z",
     "shell.execute_reply": "2023-04-04T16:39:12.986914Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit the pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "pipe.fit(X_train, y_train)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:39:14.630942Z",
     "iopub.execute_input": "2023-04-04T16:39:14.631905Z",
     "iopub.status.idle": "2023-04-04T16:40:10.537348Z",
     "shell.execute_reply.started": "2023-04-04T16:39:14.631830Z",
     "shell.execute_reply": "2023-04-04T16:40:10.535934Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "[16:39:15] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n[16:39:15] WARNING: ../src/learner.cc:627: \nParameters: { \"min_child_samples\", \"min_split_gain\", \"verbose\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n",
     "output_type": "stream"
    },
    {
     "execution_count": 14,
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('scaler',\n                                                                   StandardScaler())]),\n                                                  Index(['myear', 'km_driven', 'ip', 'Displacement', 'No of Cylinder',\n       'Valves per Cylinder', 'Width', 'Wheel Base', 'Front Tread',\n       'Kerb Weight', 'Seats', 'Turning Radius', 'Top Speed', 'Acceleration',\n       'Doors', 'mileage_new', 'Alloy Wheel Size', 'Max Power Deliver...\n                              importance_type='gain',\n                              interaction_constraints='',\n                              learning_rate=0.08363996779482333, max_bin=256,\n                              max_cat_to_onehot=4, max_delta_step=0,\n                              max_depth=7, max_leaves=0, min_child_samples=14,\n                              min_child_weight=1, min_split_gain=0.0,\n                              missing=nan, monotone_constraints='()',\n                              n_estimators=1000, n_jobs=-1, num_parallel_tree=1,\n                              objective='reg:linear', predictor='auto', ...))])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make some predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Calculate the MAPE and MAE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAPE: {mape}\")\n",
    "print(f\"MAE: {mae}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T16:45:18.526831Z",
     "iopub.execute_input": "2023-04-04T16:45:18.527360Z",
     "iopub.status.idle": "2023-04-04T16:45:18.970587Z",
     "shell.execute_reply.started": "2023-04-04T16:45:18.527324Z",
     "shell.execute_reply": "2023-04-04T16:45:18.969529Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": "MAPE: 0.11695463710664752\nMAE: 78025.79261436974\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparamter Optimization usin Optuna HyperBand"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def objective(trial, pipeline, X, y):\n",
    "    param_grid = {\n",
    "        \"tree_method\": \"hist\", # change to gpu_hist if a gpu is available\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"single_precision_histogram\": True,\n",
    "        \"importance_type\": \"gain\",\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1000, 2000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_categorical(\"max_depth\", [5,7,9,11,13,15,17]),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 300),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1),\n",
    "        \"reg_lambda\": trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        pipeline['model'].set_params(\n",
    "            n_jobs= -1,\n",
    "            **param_grid\n",
    "        )\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        preds = pipeline.predict(X_test)\n",
    "        cv_scores[idx] = mean_absolute_percentage_error(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T17:49:57.951156Z",
     "iopub.execute_input": "2023-04-04T17:49:57.951771Z",
     "iopub.status.idle": "2023-04-04T17:49:57.967317Z",
     "shell.execute_reply.started": "2023-04-04T17:49:57.951724Z",
     "shell.execute_reply": "2023-04-04T17:49:57.966055Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the XGBoost model\n",
    "xgb_model = xgboost.XGBRegressor()\n",
    "\n",
    "# Define the full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb_model)\n",
    "])\n",
    "\n",
    "# Define the Optuna search algorithm\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(lambda trial: objective(trial, pipeline, X_train, y_train), n_trials=50, timeout=None)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T17:50:25.336132Z",
     "iopub.execute_input": "2023-04-04T17:50:25.336573Z",
     "iopub.status.idle": "2023-04-04T22:20:08.791321Z",
     "shell.execute_reply.started": "2023-04-04T17:50:25.336536Z",
     "shell.execute_reply": "2023-04-04T22:20:08.789139Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "text": "\u001B[32m[I 2023-04-04 17:50:25,340]\u001B[0m A new study created in memory with name: no-name-b0054549-12f7-4a89-9843-8ec7aa8fe37f\u001B[0m\n\u001B[32m[I 2023-04-04 18:01:09,757]\u001B[0m Trial 0 finished with value: 0.12576865870555248 and parameters: {'n_estimators': 2000, 'learning_rate': 0.1205712628744377, 'max_depth': 13, 'min_child_weight': 7, 'subsample': 0.9729188669457949, 'colsample_bytree': 0.8491983767203796, 'reg_lambda': 0.0070689749506246055, 'reg_alpha': 0.005337032762603957}. Best is trial 0 with value: 0.12576865870555248.\u001B[0m\n\u001B[32m[I 2023-04-04 18:04:28,657]\u001B[0m Trial 1 finished with value: 0.1420403798131069 and parameters: {'n_estimators': 2000, 'learning_rate': 0.05958389350068958, 'max_depth': 9, 'min_child_weight': 236, 'subsample': 0.2797064039425238, 'colsample_bytree': 0.5628109945722505, 'reg_lambda': 0.23423849847112907, 'reg_alpha': 0.0015339162591163618}. Best is trial 0 with value: 0.12576865870555248.\u001B[0m\n\u001B[32m[I 2023-04-04 18:05:38,114]\u001B[0m Trial 2 finished with value: 0.15512999768373253 and parameters: {'n_estimators': 1000, 'learning_rate': 0.012476394272569451, 'max_depth': 7, 'min_child_weight': 37, 'subsample': 0.5456592191001431, 'colsample_bytree': 0.13094966900369656, 'reg_lambda': 4.337920697490942, 'reg_alpha': 0.010842262717330166}. Best is trial 0 with value: 0.12576865870555248.\u001B[0m\n\u001B[32m[I 2023-04-04 18:06:50,341]\u001B[0m Trial 3 finished with value: 0.16442889358917637 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05864129169696527, 'max_depth': 9, 'min_child_weight': 277, 'subsample': 0.17964325184672755, 'colsample_bytree': 0.27638457617723067, 'reg_lambda': 0.0015167330688076208, 'reg_alpha': 0.02001342062287998}. Best is trial 0 with value: 0.12576865870555248.\u001B[0m\n\u001B[32m[I 2023-04-04 18:08:00,286]\u001B[0m Trial 4 finished with value: 0.16375590485723004 and parameters: {'n_estimators': 1000, 'learning_rate': 0.16755052359850303, 'max_depth': 17, 'min_child_weight': 232, 'subsample': 0.2788441133807552, 'colsample_bytree': 0.10496990541124217, 'reg_lambda': 1.8274508859816028, 'reg_alpha': 0.6720930050156113}. Best is trial 0 with value: 0.12576865870555248.\u001B[0m\n\u001B[32m[I 2023-04-04 18:12:47,747]\u001B[0m Trial 5 finished with value: 0.13239381901340752 and parameters: {'n_estimators': 2000, 'learning_rate': 0.012863908101989912, 'max_depth': 9, 'min_child_weight': 98, 'subsample': 0.7566455605042577, 'colsample_bytree': 0.6738017242196918, 'reg_lambda': 3.53875886477924, 'reg_alpha': 0.0774211647399625}. Best is trial 0 with value: 0.12576865870555248.\u001B[0m\n\u001B[32m[I 2023-04-04 18:15:54,931]\u001B[0m Trial 6 finished with value: 0.12416733024091706 and parameters: {'n_estimators': 2000, 'learning_rate': 0.13297554090738672, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.6727693701374023, 'colsample_bytree': 0.382920382968694, 'reg_lambda': 0.1082138291061399, 'reg_alpha': 4.268407710065496}. Best is trial 6 with value: 0.12416733024091706.\u001B[0m\n\u001B[32m[I 2023-04-04 18:19:32,471]\u001B[0m Trial 7 finished with value: 0.12881058101538012 and parameters: {'n_estimators': 2000, 'learning_rate': 0.1306293138834092, 'max_depth': 13, 'min_child_weight': 262, 'subsample': 0.823304869209203, 'colsample_bytree': 0.2679130529974323, 'reg_lambda': 3.7173717478250508, 'reg_alpha': 0.1436709513866423}. Best is trial 6 with value: 0.12416733024091706.\u001B[0m\n\u001B[32m[I 2023-04-04 18:22:53,634]\u001B[0m Trial 8 finished with value: 0.13259651256483618 and parameters: {'n_estimators': 2000, 'learning_rate': 0.02949372944095386, 'max_depth': 13, 'min_child_weight': 126, 'subsample': 0.29989702942365726, 'colsample_bytree': 0.20787883060031453, 'reg_lambda': 0.022410971619109515, 'reg_alpha': 5.910698619088545}. Best is trial 6 with value: 0.12416733024091706.\u001B[0m\n\u001B[32m[I 2023-04-04 18:26:54,781]\u001B[0m Trial 9 finished with value: 0.12269859188848509 and parameters: {'n_estimators': 2000, 'learning_rate': 0.10925573591447926, 'max_depth': 7, 'min_child_weight': 12, 'subsample': 0.6486079005819072, 'colsample_bytree': 0.5524111209059753, 'reg_lambda': 0.001606626792172771, 'reg_alpha': 0.01301924671436158}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 18:31:31,094]\u001B[0m Trial 10 finished with value: 0.1312118404869321 and parameters: {'n_estimators': 1000, 'learning_rate': 0.21424085987579888, 'max_depth': 15, 'min_child_weight': 75, 'subsample': 0.5522780959073166, 'colsample_bytree': 0.9168983157542658, 'reg_lambda': 0.001149581347374969, 'reg_alpha': 0.0011648625905704738}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 18:34:09,443]\u001B[0m Trial 11 finished with value: 0.13800568796154783 and parameters: {'n_estimators': 2000, 'learning_rate': 0.29222994293620336, 'max_depth': 7, 'min_child_weight': 168, 'subsample': 0.5841795979027358, 'colsample_bytree': 0.42989175968725424, 'reg_lambda': 0.09865236473626507, 'reg_alpha': 5.758533894133849}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 18:36:28,862]\u001B[0m Trial 12 finished with value: 0.12720895191598652 and parameters: {'n_estimators': 2000, 'learning_rate': 0.09475198236434572, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.6877028441297922, 'colsample_bytree': 0.43173511116033086, 'reg_lambda': 0.019952529689744123, 'reg_alpha': 0.9005736436415646}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 18:41:57,079]\u001B[0m Trial 13 finished with value: 0.12506477240988295 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0916892625649698, 'max_depth': 11, 'min_child_weight': 47, 'subsample': 0.4394673014083075, 'colsample_bytree': 0.694770152763058, 'reg_lambda': 0.18091728041976277, 'reg_alpha': 0.04652629106902196}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 18:44:43,487]\u001B[0m Trial 14 finished with value: 0.12815029735860006 and parameters: {'n_estimators': 2000, 'learning_rate': 0.19497872856607984, 'max_depth': 7, 'min_child_weight': 167, 'subsample': 0.8492863679606366, 'colsample_bytree': 0.43711499824929834, 'reg_lambda': 0.004009936843290633, 'reg_alpha': 0.43613295009891834}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 18:47:55,681]\u001B[0m Trial 15 finished with value: 0.12625919525828755 and parameters: {'n_estimators': 2000, 'learning_rate': 0.08774928405647804, 'max_depth': 7, 'min_child_weight': 58, 'subsample': 0.6554790600760033, 'colsample_bytree': 0.5453148924891298, 'reg_lambda': 0.44369124423312867, 'reg_alpha': 1.508625542422027}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 18:50:28,413]\u001B[0m Trial 16 finished with value: 0.13325936725551274 and parameters: {'n_estimators': 2000, 'learning_rate': 0.045146577922274486, 'max_depth': 7, 'min_child_weight': 114, 'subsample': 0.46248718507877795, 'colsample_bytree': 0.339624108200663, 'reg_lambda': 0.07423118943207362, 'reg_alpha': 0.1439778713666387}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 18:56:57,779]\u001B[0m Trial 17 finished with value: 0.1423293096977926 and parameters: {'n_estimators': 2000, 'learning_rate': 0.27993465548464275, 'max_depth': 11, 'min_child_weight': 23, 'subsample': 0.6914307738948051, 'colsample_bytree': 0.3532728336210634, 'reg_lambda': 0.031018550187224745, 'reg_alpha': 7.645101446175259}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 18:58:13,703]\u001B[0m Trial 18 finished with value: 0.1323410775157458 and parameters: {'n_estimators': 1000, 'learning_rate': 0.14168770938702407, 'max_depth': 5, 'min_child_weight': 82, 'subsample': 0.8162896992417841, 'colsample_bytree': 0.5380362224271434, 'reg_lambda': 0.006545598047072013, 'reg_alpha': 2.106734482546315}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 19:05:44,543]\u001B[0m Trial 19 finished with value: 0.12787629607915965 and parameters: {'n_estimators': 2000, 'learning_rate': 0.1768717828031212, 'max_depth': 15, 'min_child_weight': 141, 'subsample': 0.9176430103461601, 'colsample_bytree': 0.6904394509793828, 'reg_lambda': 0.668081688512815, 'reg_alpha': 0.2827169934125093}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 19:12:17,913]\u001B[0m Trial 20 finished with value: 0.12755421596050703 and parameters: {'n_estimators': 2000, 'learning_rate': 0.116141081159003, 'max_depth': 17, 'min_child_weight': 203, 'subsample': 0.7285642092596982, 'colsample_bytree': 0.49888606723612167, 'reg_lambda': 0.047781810234185214, 'reg_alpha': 0.02960265586425192}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 19:17:43,214]\u001B[0m Trial 21 finished with value: 0.12434746229244395 and parameters: {'n_estimators': 2000, 'learning_rate': 0.08838645936462054, 'max_depth': 11, 'min_child_weight': 36, 'subsample': 0.47101966272546003, 'colsample_bytree': 0.6452961942531769, 'reg_lambda': 0.19131379130640666, 'reg_alpha': 0.0647511072312936}. Best is trial 9 with value: 0.12269859188848509.\u001B[0m\n\u001B[32m[I 2023-04-04 19:23:51,878]\u001B[0m Trial 22 finished with value: 0.12129936067185294 and parameters: {'n_estimators': 2000, 'learning_rate': 0.07883412884105272, 'max_depth': 11, 'min_child_weight': 29, 'subsample': 0.6105441897763102, 'colsample_bytree': 0.6173118708175437, 'reg_lambda': 0.14790062175066665, 'reg_alpha': 0.058984842676552324}. Best is trial 22 with value: 0.12129936067185294.\u001B[0m\n\u001B[32m[I 2023-04-04 19:33:05,017]\u001B[0m Trial 23 finished with value: 0.12232854405144929 and parameters: {'n_estimators': 2000, 'learning_rate': 0.06862513227792151, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.6073387181222152, 'colsample_bytree': 0.7773149923563916, 'reg_lambda': 0.05520350166411603, 'reg_alpha': 0.24866995860669797}. Best is trial 22 with value: 0.12129936067185294.\u001B[0m\n\u001B[32m[I 2023-04-04 19:38:49,001]\u001B[0m Trial 24 finished with value: 0.12286547322820582 and parameters: {'n_estimators': 2000, 'learning_rate': 0.06498343047247693, 'max_depth': 11, 'min_child_weight': 61, 'subsample': 0.6251853559757903, 'colsample_bytree': 0.7549637983040894, 'reg_lambda': 0.01620824402904987, 'reg_alpha': 0.17860352181840422}. Best is trial 22 with value: 0.12129936067185294.\u001B[0m\n\u001B[32m[I 2023-04-04 19:46:02,344]\u001B[0m Trial 25 finished with value: 0.12159557626855519 and parameters: {'n_estimators': 2000, 'learning_rate': 0.040383700461943804, 'max_depth': 11, 'min_child_weight': 30, 'subsample': 0.6010947131081262, 'colsample_bytree': 0.8026013612136351, 'reg_lambda': 0.0499143494774823, 'reg_alpha': 0.04528400541039168}. Best is trial 22 with value: 0.12129936067185294.\u001B[0m\n\u001B[32m[I 2023-04-04 19:49:34,303]\u001B[0m Trial 26 finished with value: 0.12883379202240036 and parameters: {'n_estimators': 1000, 'learning_rate': 0.04132375919756147, 'max_depth': 11, 'min_child_weight': 99, 'subsample': 0.5335502734957913, 'colsample_bytree': 0.9902682078797934, 'reg_lambda': 0.06139498522796698, 'reg_alpha': 0.265977556768874}. Best is trial 22 with value: 0.12129936067185294.\u001B[0m\n\u001B[32m[I 2023-04-04 19:56:37,541]\u001B[0m Trial 27 finished with value: 0.12097691110074753 and parameters: {'n_estimators': 2000, 'learning_rate': 0.034411857275679664, 'max_depth': 11, 'min_child_weight': 38, 'subsample': 0.7502849596046428, 'colsample_bytree': 0.7894915077251272, 'reg_lambda': 0.037196499263965364, 'reg_alpha': 0.08609573721753028}. Best is trial 27 with value: 0.12097691110074753.\u001B[0m\n\u001B[32m[I 2023-04-04 20:02:49,694]\u001B[0m Trial 28 finished with value: 0.12375896367333734 and parameters: {'n_estimators': 2000, 'learning_rate': 0.029195777596404602, 'max_depth': 11, 'min_child_weight': 77, 'subsample': 0.7578998707846138, 'colsample_bytree': 0.7988952923373268, 'reg_lambda': 0.039770383430284634, 'reg_alpha': 0.08339678148039535}. Best is trial 27 with value: 0.12097691110074753.\u001B[0m\n\u001B[32m[I 2023-04-04 20:10:07,906]\u001B[0m Trial 29 finished with value: 0.12122012745424145 and parameters: {'n_estimators': 2000, 'learning_rate': 0.03611062200712138, 'max_depth': 11, 'min_child_weight': 41, 'subsample': 0.7591897373793559, 'colsample_bytree': 0.8586956101436257, 'reg_lambda': 0.009567987737796702, 'reg_alpha': 0.04145437569835856}. Best is trial 27 with value: 0.12097691110074753.\u001B[0m\n\u001B[32m[I 2023-04-04 20:17:19,180]\u001B[0m Trial 30 finished with value: 0.12216628988073638 and parameters: {'n_estimators': 2000, 'learning_rate': 0.028928011513375547, 'max_depth': 11, 'min_child_weight': 57, 'subsample': 0.9917016809244315, 'colsample_bytree': 0.8698138583934116, 'reg_lambda': 0.013544479157171857, 'reg_alpha': 0.028197312782280937}. Best is trial 27 with value: 0.12097691110074753.\u001B[0m\n\u001B[32m[I 2023-04-04 20:24:34,105]\u001B[0m Trial 31 finished with value: 0.12097751910926172 and parameters: {'n_estimators': 2000, 'learning_rate': 0.039013463930270595, 'max_depth': 11, 'min_child_weight': 40, 'subsample': 0.7581969559566564, 'colsample_bytree': 0.843068642252525, 'reg_lambda': 0.011537431023437753, 'reg_alpha': 0.04298665671625485}. Best is trial 27 with value: 0.12097691110074753.\u001B[0m\n\u001B[32m[I 2023-04-04 20:33:44,135]\u001B[0m Trial 32 finished with value: 0.11961483279021286 and parameters: {'n_estimators': 2000, 'learning_rate': 0.04766173848322245, 'max_depth': 11, 'min_child_weight': 25, 'subsample': 0.779462219667542, 'colsample_bytree': 0.8727237546227111, 'reg_lambda': 0.007626920658245195, 'reg_alpha': 0.004766516084891841}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 20:40:59,343]\u001B[0m Trial 33 finished with value: 0.12071116079359012 and parameters: {'n_estimators': 2000, 'learning_rate': 0.05179728601963154, 'max_depth': 11, 'min_child_weight': 47, 'subsample': 0.907457741233203, 'colsample_bytree': 0.8694331798550432, 'reg_lambda': 0.009285980575001171, 'reg_alpha': 0.005110247151730601}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 20:47:50,995]\u001B[0m Trial 34 finished with value: 0.12195957938001437 and parameters: {'n_estimators': 2000, 'learning_rate': 0.04918174670386913, 'max_depth': 11, 'min_child_weight': 69, 'subsample': 0.918995466844875, 'colsample_bytree': 0.9155373195381463, 'reg_lambda': 0.005346545744165667, 'reg_alpha': 0.003462126015715644}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 20:52:43,530]\u001B[0m Trial 35 finished with value: 0.12179105202719032 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05580621182599265, 'max_depth': 17, 'min_child_weight': 93, 'subsample': 0.9012997532845453, 'colsample_bytree': 0.7420724845021727, 'reg_lambda': 0.00899383054206036, 'reg_alpha': 0.0055687167070911925}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 20:58:12,692]\u001B[0m Trial 36 finished with value: 0.12111418900643312 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0520931988505816, 'max_depth': 9, 'min_child_weight': 50, 'subsample': 0.9625179369262581, 'colsample_bytree': 0.8260231242220376, 'reg_lambda': 0.0035203754375648915, 'reg_alpha': 0.007073074747612278}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 21:04:30,335]\u001B[0m Trial 37 finished with value: 0.12189369210377805 and parameters: {'n_estimators': 1000, 'learning_rate': 0.035523989946590416, 'max_depth': 11, 'min_child_weight': 20, 'subsample': 0.8655458572573438, 'colsample_bytree': 0.9927608188269235, 'reg_lambda': 0.013224953993258709, 'reg_alpha': 0.004124159222754184}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 21:12:35,038]\u001B[0m Trial 38 finished with value: 0.12494561140428598 and parameters: {'n_estimators': 2000, 'learning_rate': 0.02053436339877476, 'max_depth': 13, 'min_child_weight': 112, 'subsample': 0.7961465474333301, 'colsample_bytree': 0.8973621178641201, 'reg_lambda': 0.024971965900528997, 'reg_alpha': 0.01659918665538293}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 21:15:48,405]\u001B[0m Trial 39 finished with value: 0.12745763869577842 and parameters: {'n_estimators': 2000, 'learning_rate': 0.06624950948187504, 'max_depth': 5, 'min_child_weight': 42, 'subsample': 0.7975748462132634, 'colsample_bytree': 0.844390427170861, 'reg_lambda': 0.0028562029036100873, 'reg_alpha': 0.002122740952056249}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 21:21:20,266]\u001B[0m Trial 40 finished with value: 0.12775893647646966 and parameters: {'n_estimators': 2000, 'learning_rate': 0.023482036902377632, 'max_depth': 9, 'min_child_weight': 89, 'subsample': 0.8674876025375926, 'colsample_bytree': 0.9504178714287687, 'reg_lambda': 0.011432642957738796, 'reg_alpha': 0.00927478636185982}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 21:26:44,759]\u001B[0m Trial 41 finished with value: 0.12183266177014321 and parameters: {'n_estimators': 2000, 'learning_rate': 0.05009852136667264, 'max_depth': 9, 'min_child_weight': 51, 'subsample': 0.997747364774979, 'colsample_bytree': 0.8255994749680384, 'reg_lambda': 0.00419919286144253, 'reg_alpha': 0.008315627489144177}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 21:34:11,254]\u001B[0m Trial 42 finished with value: 0.11977880064659696 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0563500659637297, 'max_depth': 9, 'min_child_weight': 16, 'subsample': 0.9547811026883033, 'colsample_bytree': 0.8723051465833175, 'reg_lambda': 0.007707649108583048, 'reg_alpha': 0.01851000022761828}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 21:41:45,422]\u001B[0m Trial 43 finished with value: 0.11979503368303923 and parameters: {'n_estimators': 2000, 'learning_rate': 0.055844826710811514, 'max_depth': 9, 'min_child_weight': 16, 'subsample': 0.954631389362943, 'colsample_bytree': 0.8760208273218364, 'reg_lambda': 0.006914908916048816, 'reg_alpha': 0.019564802793132722}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 21:49:25,777]\u001B[0m Trial 44 finished with value: 0.11979790951276581 and parameters: {'n_estimators': 2000, 'learning_rate': 0.05777622839889996, 'max_depth': 9, 'min_child_weight': 17, 'subsample': 0.9563878487550934, 'colsample_bytree': 0.8895876020151819, 'reg_lambda': 0.006821727211196412, 'reg_alpha': 0.013375891477089941}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 21:57:34,348]\u001B[0m Trial 45 finished with value: 0.11974711105221862 and parameters: {'n_estimators': 2000, 'learning_rate': 0.05562647695801551, 'max_depth': 9, 'min_child_weight': 13, 'subsample': 0.9528453719721187, 'colsample_bytree': 0.9490415634870022, 'reg_lambda': 0.00726605964524518, 'reg_alpha': 0.013411283603157553}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 22:01:55,575]\u001B[0m Trial 46 finished with value: 0.12107120789344825 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06216806399556116, 'max_depth': 9, 'min_child_weight': 15, 'subsample': 0.9519329801216605, 'colsample_bytree': 0.9579952595124452, 'reg_lambda': 0.0023709764328232385, 'reg_alpha': 0.014037131702495063}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 22:09:39,256]\u001B[0m Trial 47 finished with value: 0.1209788552648627 and parameters: {'n_estimators': 2000, 'learning_rate': 0.07318246634130919, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9516634055915023, 'colsample_bytree': 0.9403906851577832, 'reg_lambda': 0.006183066076665901, 'reg_alpha': 0.019533950652804777}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[32m[I 2023-04-04 22:17:04,238]\u001B[0m Trial 48 finished with value: 0.12006710422359665 and parameters: {'n_estimators': 2000, 'learning_rate': 0.05829621970053374, 'max_depth': 9, 'min_child_weight': 19, 'subsample': 0.9591577742411258, 'colsample_bytree': 0.8983725692188687, 'reg_lambda': 0.001978296448523844, 'reg_alpha': 0.010677131897485283}. Best is trial 32 with value: 0.11961483279021286.\u001B[0m\n\u001B[33m[W 2023-04-04 22:20:08,739]\u001B[0m Trial 49 failed with parameters: {'n_estimators': 2000, 'learning_rate': 0.0608185648722516, 'max_depth': 9, 'min_child_weight': 299, 'subsample': 0.8794064138766904, 'colsample_bytree': 0.8944323713269376, 'reg_lambda': 0.00164124129453287, 'reg_alpha': 0.013340467239010534} because of the following error: KeyboardInterrupt().\u001B[0m\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_26/1480570999.py\", line 12, in <lambda>\n    study.optimize(lambda trial: objective(trial, pipeline, X_train, y_train), n_trials=50, timeout=None)\n  File \"/tmp/ipykernel_26/3277947028.py\", line 32, in objective\n    pipeline.fit(X_train, y_train)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\", line 394, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/opt/conda/lib/python3.7/site-packages/xgboost/core.py\", line 575, in inner_f\n    return f(**kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\", line 972, in fit\n    callbacks=callbacks,\n  File \"/opt/conda/lib/python3.7/site-packages/xgboost/core.py\", line 575, in inner_f\n    return f(**kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/xgboost/training.py\", line 181, in train\n    bst.update(dtrain, i, obj)\n  File \"/opt/conda/lib/python3.7/site-packages/xgboost/core.py\", line 1780, in update\n    dtrain.handle))\nKeyboardInterrupt\n\u001B[33m[W 2023-04-04 22:20:08,741]\u001B[0m Trial 49 failed with value None.\u001B[0m\n",
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_26/1480570999.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;31m# Define the Optuna search algorithm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mstudy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptuna\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_study\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirection\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'minimize'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msampler\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moptuna\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msamplers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTPESampler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m42\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0mstudy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mtrial\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mobjective\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_trials\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/study.py\u001B[0m in \u001B[0;36moptimize\u001B[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m    432\u001B[0m             \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    433\u001B[0m             \u001B[0mgc_after_trial\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgc_after_trial\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 434\u001B[0;31m             \u001B[0mshow_progress_bar\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshow_progress_bar\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    435\u001B[0m         )\n\u001B[1;32m    436\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001B[0m in \u001B[0;36m_optimize\u001B[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m     74\u001B[0m                 \u001B[0mreseed_sampler_rng\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m                 \u001B[0mtime_start\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 76\u001B[0;31m                 \u001B[0mprogress_bar\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mprogress_bar\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     77\u001B[0m             )\n\u001B[1;32m     78\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001B[0m in \u001B[0;36m_optimize_sequential\u001B[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[1;32m    161\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 163\u001B[0;31m             \u001B[0mfrozen_trial\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_run_trial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstudy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    164\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m             \u001B[0;31m# The following line mitigates memory problems that can be occurred in some\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    249\u001B[0m         \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc_err\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    250\u001B[0m     ):\n\u001B[0;32m--> 251\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mfunc_err\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    252\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mfrozen_trial\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    198\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mget_heartbeat_thread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_trial_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstudy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_storage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    199\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 200\u001B[0;31m             \u001B[0mvalue_or_values\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    201\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrialPruned\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    202\u001B[0m             \u001B[0;31m# TODO(mamu): Handle multi-objective cases.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_26/1480570999.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(trial)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;31m# Define the Optuna search algorithm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mstudy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptuna\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_study\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirection\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'minimize'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msampler\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moptuna\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msamplers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTPESampler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m42\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0mstudy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mtrial\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mobjective\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_trials\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_26/3277947028.py\u001B[0m in \u001B[0;36mobjective\u001B[0;34m(trial, pipeline, X, y)\u001B[0m\n\u001B[1;32m     30\u001B[0m             \u001B[0;34m**\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m         )\n\u001B[0;32m---> 32\u001B[0;31m         \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[0mpreds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    392\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_final_estimator\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m\"passthrough\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    393\u001B[0m                 \u001B[0mfit_params_last_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfit_params_steps\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 394\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_final_estimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params_last_step\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    395\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    396\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    573\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 575\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    576\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    577\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[1;32m    970\u001B[0m             \u001B[0mverbose_eval\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    971\u001B[0m             \u001B[0mxgb_model\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 972\u001B[0;31m             \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    973\u001B[0m         )\n\u001B[1;32m    974\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    573\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 575\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    576\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    577\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[1;32m    179\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcb_container\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbefore_iteration\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbst\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    180\u001B[0m             \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 181\u001B[0;31m         \u001B[0mbst\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    182\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcb_container\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mafter_iteration\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbst\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    183\u001B[0m             \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[1;32m   1778\u001B[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001B[1;32m   1779\u001B[0m                                                     \u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mc_int\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miteration\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1780\u001B[0;31m                                                     dtrain.handle))\n\u001B[0m\u001B[1;32m   1781\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1782\u001B[0m             \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_margin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trial = study.best_trial\n",
    "best_params = trial.params\n",
    "\n",
    "best_xgbmodel = xgboost.XGBRegressor(\n",
    "    **best_params, \n",
    "    random_state=42, \n",
    "    n_jobs=-1, \n",
    "    tree_method=\"hist\", \n",
    "    objective=\"reg:squarederror\", \n",
    "    single_precision_histogram=True,\n",
    "    importance_type=\"gain\"\n",
    ")\n",
    "\n",
    "# Define the full pipeline\n",
    "best_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', best_xgbmodel)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T22:20:35.645904Z",
     "iopub.execute_input": "2023-04-04T22:20:35.646754Z",
     "iopub.status.idle": "2023-04-04T22:22:52.480754Z",
     "shell.execute_reply.started": "2023-04-04T22:20:35.646707Z",
     "shell.execute_reply": "2023-04-04T22:22:52.479294Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": [
    {
     "execution_count": 35,
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('scaler',\n                                                                   StandardScaler())]),\n                                                  Index(['myear', 'km_driven', 'ip', 'Displacement', 'No of Cylinder',\n       'Valves per Cylinder', 'Width', 'Wheel Base', 'Front Tread',\n       'Kerb Weight', 'Seats', 'Turning Radius', 'Top Speed', 'Acceleration',\n       'Doors', 'mileage_new', 'Alloy Wheel Size', 'Max Power Deliver...\n                              importance_type='gain',\n                              interaction_constraints='',\n                              learning_rate=0.04766173848322245, max_bin=256,\n                              max_cat_to_onehot=4, max_delta_step=0,\n                              max_depth=11, max_leaves=0, min_child_weight=25,\n                              missing=nan, monotone_constraints='()',\n                              n_estimators=2000, n_jobs=-1, num_parallel_tree=1,\n                              predictor='auto', random_state=42,\n                              reg_alpha=0.004766516084891841,\n                              reg_lambda=0.007626920658245195, ...))])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the MAPE and MAE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAPE: {mape}\")\n",
    "print(f\"MAE: {mae}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-04T22:24:06.539023Z",
     "iopub.execute_input": "2023-04-04T22:24:06.539532Z",
     "iopub.status.idle": "2023-04-04T22:24:07.738331Z",
     "shell.execute_reply.started": "2023-04-04T22:24:06.539493Z",
     "shell.execute_reply": "2023-04-04T22:24:07.737260Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": "MAPE: 0.11816291390223506\nMAE: 80835.50288459765\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
